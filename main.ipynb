{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7691610e-65b8-4955-8a4d-27fca9b76373",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb06abd-6a59-4298-976d-f2cd487e9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import dataset as d\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26806a2c-9755-45f2-b945-4cdc26dc4165",
   "metadata": {},
   "source": [
    "## Hyperparameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaffb268-9a47-45da-942b-f6b60b52b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':10, #Your Epochs,\n",
    "    'LR':1e-5, #Your Learning Rate,\n",
    "    'BATCH_SIZE': 128, #Your Batch Size,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0fbf6-43b7-4d09-81da-149147f5fa44",
   "metadata": {},
   "source": [
    "## Fixed Random-Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0e6a64-4f23-4813-9426-e0b56ce797ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae6476-b1cc-434b-8f86-5149a283858d",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.py 의 CustomDataset 클래스 사용\n",
    "import dataset as d\n",
    "from util.preprocessing import  *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mean = (0.42008194, 0.3838274, 0.34902292)\n",
    "train_Std = (0.23926373, 0.22593886, 0.22363442)\n",
    "\n",
    "test_mean = (0.4216005, 0.38125762, 0.34539804)\n",
    "test_Std = (0.23252015, 0.21890979, 0.21627444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a601035f-45f0-4855-97a3-b58cf408a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/open/train.csv')\n",
    "test_data = pd.read_csv('./data/open/test.csv')\n",
    "train_transform = d.ImageTransForm(CFG['IMG_SIZE'], train_mean, train_Std)\n",
    "test_transform = d.ImageTransForm(CFG['IMG_SIZE'], test_mean, test_Std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = d.CustomDataset(train_data, 'train', transform=train_transform)\n",
    "test_dataset = d.CustomDataset(test_data, 'test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5263, -1.4115, -1.5099,  ..., -1.2804, -1.3132, -1.4443],\n",
       "          [-1.5263, -1.4443, -1.4935,  ..., -1.3624, -1.2968, -1.5263],\n",
       "          [-1.5263, -1.4771, -1.5099,  ..., -1.4607, -1.0182, -1.1821],\n",
       "          ...,\n",
       "          [-0.5756, -0.4773, -0.3953,  ..., -1.0018, -1.0673, -1.2640],\n",
       "          [-1.1165, -0.9198, -0.6412,  ..., -1.2149, -1.1985, -1.0018],\n",
       "          [-0.6740, -0.5920, -0.4773,  ..., -1.2149, -1.2804, -0.9854]],\n",
       "\n",
       "         [[-1.4732, -1.3517, -1.4558,  ..., -1.1955, -1.2302, -1.3343],\n",
       "          [-1.4732, -1.3864, -1.4385,  ..., -1.2822, -1.2128, -1.4211],\n",
       "          [-1.4732, -1.4211, -1.4558,  ..., -1.3864, -0.9004, -1.0913],\n",
       "          ...,\n",
       "          [-0.8483, -0.7789, -0.7615,  ..., -1.0913, -1.1608, -1.3517],\n",
       "          [-1.2822, -1.0393, -0.8657,  ..., -1.3343, -1.2822, -1.1434],\n",
       "          [-1.0219, -0.8657, -0.8483,  ..., -1.2822, -1.3690, -1.1434]],\n",
       "\n",
       "         [[-1.4029, -1.2977, -1.4029,  ..., -1.2100, -1.2626, -1.3853],\n",
       "          [-1.4029, -1.3327, -1.3853,  ..., -1.2801, -1.2450, -1.4730],\n",
       "          [-1.4204, -1.3678, -1.4029,  ..., -1.3853, -0.9820, -1.1749],\n",
       "          ...,\n",
       "          [-1.1223, -0.9820, -0.9995,  ..., -1.1749, -1.2275, -1.3678],\n",
       "          [-1.4379, -1.2977, -1.1924,  ..., -1.3152, -1.2977, -1.1924],\n",
       "          [-1.1924, -1.0697, -1.1223,  ..., -1.2450, -1.2977, -1.1398]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1947,  0.1455,  0.0800,  ...,  0.4733,  0.3586,  0.4406],\n",
       "          [ 0.1783,  0.1291,  0.0800,  ...,  0.4406,  0.3914,  0.4733],\n",
       "          [ 0.1127,  0.0800,  0.0308,  ...,  0.4078,  0.4406,  0.6536],\n",
       "          ...,\n",
       "          [-0.8215, -0.5101, -0.4937,  ..., -0.3790, -0.3298, -0.1659],\n",
       "          [-0.4937, -0.4445, -0.5920,  ..., -0.2478, -0.2642, -0.2478],\n",
       "          [-0.4937, -0.6248, -0.6084,  ..., -0.2642, -0.2642, -0.4445]],\n",
       "\n",
       "         [[ 0.4708,  0.4014,  0.3319,  ...,  0.6096,  0.4881,  0.5923],\n",
       "          [ 0.4534,  0.3840,  0.3319,  ...,  0.5749,  0.5229,  0.6096],\n",
       "          [ 0.3666,  0.3319,  0.2799,  ...,  0.5402,  0.5749,  0.8006],\n",
       "          ...,\n",
       "          [-0.9698, -0.6400, -0.6227,  ..., -0.5012, -0.4491, -0.2929],\n",
       "          [-0.6227, -0.5880, -0.7442,  ..., -0.3971, -0.3971, -0.3797],\n",
       "          [-0.6227, -0.7615, -0.7615,  ..., -0.3971, -0.3971, -0.5706]],\n",
       "\n",
       "         [[ 1.2625,  1.2099,  1.1573,  ...,  0.9294,  0.8066,  0.9118],\n",
       "          [ 1.2450,  1.2099,  1.1573,  ...,  0.8943,  0.8417,  0.9294],\n",
       "          [ 1.1749,  1.1573,  1.1047,  ...,  0.8592,  0.8943,  1.1223],\n",
       "          ...,\n",
       "          [-1.1223, -0.8242, -0.7891,  ..., -0.6839, -0.6313, -0.4384],\n",
       "          [-0.7891, -0.7365, -0.8768,  ..., -0.5436, -0.5787, -0.5436],\n",
       "          [-0.8067, -0.9469, -0.9119,  ..., -0.5612, -0.5787, -0.7540]]],\n",
       "\n",
       "\n",
       "        [[[-0.6248, -0.5429, -0.2478,  ...,  0.4897,  0.9323,  0.8011],\n",
       "          [-0.6576, -0.4773, -0.1331,  ...,  0.5389,  1.0142,  0.7520],\n",
       "          [-0.7068, -0.4609,  0.0964,  ...,  0.4733,  1.0634,  0.6372],\n",
       "          ...,\n",
       "          [-0.0839,  0.2603,  0.1619,  ...,  1.6534,  1.5387,  1.1945],\n",
       "          [-0.1331,  0.1619,  0.1947,  ...,  1.6370,  1.5551,  1.2437],\n",
       "          [-0.0839,  0.1127,  0.1455,  ...,  1.7026,  1.5551,  1.2765]],\n",
       "\n",
       "         [[-0.5012, -0.4144, -0.1020,  ...,  0.6791,  1.1477,  1.0088],\n",
       "          [-0.5359, -0.3450,  0.0195,  ...,  0.7311,  1.2345,  0.9568],\n",
       "          [-0.5880, -0.3276,  0.2625,  ...,  0.6617,  1.2866,  0.8353],\n",
       "          ...,\n",
       "          [ 0.0716,  0.4361,  0.3319,  ...,  1.9114,  1.7899,  1.4254],\n",
       "          [ 0.0195,  0.3319,  0.3666,  ...,  1.8940,  1.8073,  1.4775],\n",
       "          [ 0.0716,  0.2799,  0.3146,  ...,  1.9635,  1.8073,  1.5122]],\n",
       "\n",
       "         [[-0.3507, -0.2630,  0.0526,  ...,  0.8417,  1.3152,  1.1749],\n",
       "          [-0.3858, -0.1929,  0.1753,  ...,  0.8943,  1.4028,  1.1223],\n",
       "          [-0.4384, -0.1754,  0.4208,  ...,  0.8242,  1.4554,  0.9995],\n",
       "          ...,\n",
       "          [ 0.2279,  0.5962,  0.4910,  ...,  2.0867,  1.9640,  1.5957],\n",
       "          [ 0.1753,  0.4910,  0.5261,  ...,  2.0692,  1.9815,  1.6483],\n",
       "          [ 0.2279,  0.4384,  0.4734,  ...,  2.1393,  1.9815,  1.6834]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.4242,  0.4078,  0.3422,  ...,  1.8337,  1.8173,  1.8173],\n",
       "          [ 0.3258,  0.3586,  0.3094,  ...,  1.8337,  1.8173,  1.8173],\n",
       "          [ 0.2439,  0.2767,  0.2603,  ...,  1.8337,  1.8173,  1.8173],\n",
       "          ...,\n",
       "          [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632],\n",
       "          [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632],\n",
       "          [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632]],\n",
       "\n",
       "         [[ 0.6270,  0.6270,  0.5576,  ...,  2.2585,  2.2412,  2.2412],\n",
       "          [ 0.5576,  0.5749,  0.5229,  ...,  2.2585,  2.2412,  2.2412],\n",
       "          [ 0.4881,  0.5055,  0.4708,  ...,  2.2585,  2.2412,  2.2412],\n",
       "          ...,\n",
       "          [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627],\n",
       "          [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627],\n",
       "          [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627]],\n",
       "\n",
       "         [[ 0.4208,  0.3858,  0.3156,  ...,  2.7005,  2.6829,  2.6829],\n",
       "          [ 0.2630,  0.3156,  0.2630,  ...,  2.7005,  2.6829,  2.6829],\n",
       "          [ 0.0701,  0.2279,  0.1929,  ...,  2.7005,  2.6829,  2.6829],\n",
       "          ...,\n",
       "          [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303],\n",
       "          [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303],\n",
       "          [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303]]],\n",
       "\n",
       "\n",
       "        [[[-1.7557, -1.7393, -1.7393,  ..., -0.5101, -0.4445, -1.1493],\n",
       "          [-1.7393, -1.7393, -1.7393,  ..., -0.4937, -0.1331, -0.5429],\n",
       "          [-1.7557, -1.7557, -1.7557,  ..., -0.1167,  0.0144, -0.2642],\n",
       "          ...,\n",
       "          [ 2.0632,  2.1615,  1.5059,  ...,  1.9976,  1.7026,  1.1945],\n",
       "          [ 2.0468,  2.0468,  1.6206,  ...,  2.1451,  2.3418,  2.3254],\n",
       "          [ 1.9812,  1.8993,  1.9321,  ...,  2.3090,  2.3254,  2.2926]],\n",
       "\n",
       "         [[ 2.1891,  2.2065,  2.2065,  ...,  1.0088,  1.6510,  1.9635],\n",
       "          [ 2.2238,  2.2412,  2.2412,  ...,  1.4428,  1.4081,  1.1130],\n",
       "          [ 2.2412,  2.2585,  2.2585,  ...,  1.4948,  1.5295,  0.9221],\n",
       "          ...,\n",
       "          [ 1.2171,  1.4601,  0.4187,  ...,  0.3319,  0.1931, -0.2061],\n",
       "          [ 0.8353,  0.8179,  0.2972,  ...,  0.8526,  1.0436,  1.0088],\n",
       "          [ 0.4534,  0.2972,  0.5402,  ...,  1.4601,  1.2866,  1.0262]],\n",
       "\n",
       "         [[ 2.8232,  2.8232,  2.8408,  ..., -0.6138,  0.4208,  1.5607],\n",
       "          [ 2.8408,  2.8408,  2.8232,  ..., -0.1754, -0.3332, -0.2630],\n",
       "          [ 2.8583,  2.8057,  2.7881,  ..., -0.3332, -0.1754, -0.8242],\n",
       "          ...,\n",
       "          [-1.0171, -0.6839, -1.2626,  ..., -1.3327, -1.2100, -1.2801],\n",
       "          [-0.9820, -0.7891, -1.2626,  ..., -1.4905, -1.3327, -1.3152],\n",
       "          [-1.2450, -1.2626, -1.0872,  ..., -1.1924, -1.3327, -1.3503]]],\n",
       "\n",
       "\n",
       "        [[[-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "          [-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "          [-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "          ...,\n",
       "          [-0.6576, -0.1495, -0.3462,  ...,  0.0144, -0.2314, -0.7887],\n",
       "          [-0.6740, -0.3626, -0.8051,  ...,  0.7356, -0.1331, -0.4773],\n",
       "          [-0.5920, -0.5101, -0.7231,  ...,  0.5225, -0.4281, -0.0839]],\n",
       "\n",
       "         [[-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "          [-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "          [-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "          ...,\n",
       "          [-0.3623,  0.1584,  0.0889,  ...,  0.2625,  0.1063, -0.4144],\n",
       "          [-0.2756,  0.1063, -0.2061,  ...,  1.0262,  0.1931, -0.0499],\n",
       "          [-0.1888, -0.1367, -0.1020,  ...,  0.7659, -0.0673,  0.2972]],\n",
       "\n",
       "         [[-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "          [-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "          [-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "          ...,\n",
       "          [-1.3152, -1.2626, -1.2275,  ..., -0.9645, -1.4029, -1.4379],\n",
       "          [-1.4905, -1.3853, -1.5081,  ..., -0.1754, -1.3152, -1.4029],\n",
       "          [-1.3853, -1.5081, -1.5256,  ..., -0.5085, -1.3853, -1.3678]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-1.5263, -1.4115, -1.5099,  ..., -1.2804, -1.3132, -1.4443],\n",
       "           [-1.5263, -1.4443, -1.4935,  ..., -1.3624, -1.2968, -1.5263],\n",
       "           [-1.5263, -1.4771, -1.5099,  ..., -1.4607, -1.0182, -1.1821],\n",
       "           ...,\n",
       "           [-0.5756, -0.4773, -0.3953,  ..., -1.0018, -1.0673, -1.2640],\n",
       "           [-1.1165, -0.9198, -0.6412,  ..., -1.2149, -1.1985, -1.0018],\n",
       "           [-0.6740, -0.5920, -0.4773,  ..., -1.2149, -1.2804, -0.9854]],\n",
       " \n",
       "          [[-1.4732, -1.3517, -1.4558,  ..., -1.1955, -1.2302, -1.3343],\n",
       "           [-1.4732, -1.3864, -1.4385,  ..., -1.2822, -1.2128, -1.4211],\n",
       "           [-1.4732, -1.4211, -1.4558,  ..., -1.3864, -0.9004, -1.0913],\n",
       "           ...,\n",
       "           [-0.8483, -0.7789, -0.7615,  ..., -1.0913, -1.1608, -1.3517],\n",
       "           [-1.2822, -1.0393, -0.8657,  ..., -1.3343, -1.2822, -1.1434],\n",
       "           [-1.0219, -0.8657, -0.8483,  ..., -1.2822, -1.3690, -1.1434]],\n",
       " \n",
       "          [[-1.4029, -1.2977, -1.4029,  ..., -1.2100, -1.2626, -1.3853],\n",
       "           [-1.4029, -1.3327, -1.3853,  ..., -1.2801, -1.2450, -1.4730],\n",
       "           [-1.4204, -1.3678, -1.4029,  ..., -1.3853, -0.9820, -1.1749],\n",
       "           ...,\n",
       "           [-1.1223, -0.9820, -0.9995,  ..., -1.1749, -1.2275, -1.3678],\n",
       "           [-1.4379, -1.2977, -1.1924,  ..., -1.3152, -1.2977, -1.1924],\n",
       "           [-1.1924, -1.0697, -1.1223,  ..., -1.2450, -1.2977, -1.1398]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1947,  0.1455,  0.0800,  ...,  0.4733,  0.3586,  0.4406],\n",
       "           [ 0.1783,  0.1291,  0.0800,  ...,  0.4406,  0.3914,  0.4733],\n",
       "           [ 0.1127,  0.0800,  0.0308,  ...,  0.4078,  0.4406,  0.6536],\n",
       "           ...,\n",
       "           [-0.8215, -0.5101, -0.4937,  ..., -0.3790, -0.3298, -0.1659],\n",
       "           [-0.4937, -0.4445, -0.5920,  ..., -0.2478, -0.2642, -0.2478],\n",
       "           [-0.4937, -0.6248, -0.6084,  ..., -0.2642, -0.2642, -0.4445]],\n",
       " \n",
       "          [[ 0.4708,  0.4014,  0.3319,  ...,  0.6096,  0.4881,  0.5923],\n",
       "           [ 0.4534,  0.3840,  0.3319,  ...,  0.5749,  0.5229,  0.6096],\n",
       "           [ 0.3666,  0.3319,  0.2799,  ...,  0.5402,  0.5749,  0.8006],\n",
       "           ...,\n",
       "           [-0.9698, -0.6400, -0.6227,  ..., -0.5012, -0.4491, -0.2929],\n",
       "           [-0.6227, -0.5880, -0.7442,  ..., -0.3971, -0.3971, -0.3797],\n",
       "           [-0.6227, -0.7615, -0.7615,  ..., -0.3971, -0.3971, -0.5706]],\n",
       " \n",
       "          [[ 1.2625,  1.2099,  1.1573,  ...,  0.9294,  0.8066,  0.9118],\n",
       "           [ 1.2450,  1.2099,  1.1573,  ...,  0.8943,  0.8417,  0.9294],\n",
       "           [ 1.1749,  1.1573,  1.1047,  ...,  0.8592,  0.8943,  1.1223],\n",
       "           ...,\n",
       "           [-1.1223, -0.8242, -0.7891,  ..., -0.6839, -0.6313, -0.4384],\n",
       "           [-0.7891, -0.7365, -0.8768,  ..., -0.5436, -0.5787, -0.5436],\n",
       "           [-0.8067, -0.9469, -0.9119,  ..., -0.5612, -0.5787, -0.7540]]],\n",
       " \n",
       " \n",
       "         [[[-0.6248, -0.5429, -0.2478,  ...,  0.4897,  0.9323,  0.8011],\n",
       "           [-0.6576, -0.4773, -0.1331,  ...,  0.5389,  1.0142,  0.7520],\n",
       "           [-0.7068, -0.4609,  0.0964,  ...,  0.4733,  1.0634,  0.6372],\n",
       "           ...,\n",
       "           [-0.0839,  0.2603,  0.1619,  ...,  1.6534,  1.5387,  1.1945],\n",
       "           [-0.1331,  0.1619,  0.1947,  ...,  1.6370,  1.5551,  1.2437],\n",
       "           [-0.0839,  0.1127,  0.1455,  ...,  1.7026,  1.5551,  1.2765]],\n",
       " \n",
       "          [[-0.5012, -0.4144, -0.1020,  ...,  0.6791,  1.1477,  1.0088],\n",
       "           [-0.5359, -0.3450,  0.0195,  ...,  0.7311,  1.2345,  0.9568],\n",
       "           [-0.5880, -0.3276,  0.2625,  ...,  0.6617,  1.2866,  0.8353],\n",
       "           ...,\n",
       "           [ 0.0716,  0.4361,  0.3319,  ...,  1.9114,  1.7899,  1.4254],\n",
       "           [ 0.0195,  0.3319,  0.3666,  ...,  1.8940,  1.8073,  1.4775],\n",
       "           [ 0.0716,  0.2799,  0.3146,  ...,  1.9635,  1.8073,  1.5122]],\n",
       " \n",
       "          [[-0.3507, -0.2630,  0.0526,  ...,  0.8417,  1.3152,  1.1749],\n",
       "           [-0.3858, -0.1929,  0.1753,  ...,  0.8943,  1.4028,  1.1223],\n",
       "           [-0.4384, -0.1754,  0.4208,  ...,  0.8242,  1.4554,  0.9995],\n",
       "           ...,\n",
       "           [ 0.2279,  0.5962,  0.4910,  ...,  2.0867,  1.9640,  1.5957],\n",
       "           [ 0.1753,  0.4910,  0.5261,  ...,  2.0692,  1.9815,  1.6483],\n",
       "           [ 0.2279,  0.4384,  0.4734,  ...,  2.1393,  1.9815,  1.6834]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.4242,  0.4078,  0.3422,  ...,  1.8337,  1.8173,  1.8173],\n",
       "           [ 0.3258,  0.3586,  0.3094,  ...,  1.8337,  1.8173,  1.8173],\n",
       "           [ 0.2439,  0.2767,  0.2603,  ...,  1.8337,  1.8173,  1.8173],\n",
       "           ...,\n",
       "           [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632],\n",
       "           [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632],\n",
       "           [ 1.9648,  1.9648,  1.9648,  ...,  2.0796,  2.0632,  2.0632]],\n",
       " \n",
       "          [[ 0.6270,  0.6270,  0.5576,  ...,  2.2585,  2.2412,  2.2412],\n",
       "           [ 0.5576,  0.5749,  0.5229,  ...,  2.2585,  2.2412,  2.2412],\n",
       "           [ 0.4881,  0.5055,  0.4708,  ...,  2.2585,  2.2412,  2.2412],\n",
       "           ...,\n",
       "           [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627],\n",
       "           [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627],\n",
       "           [ 2.2585,  2.2585,  2.2585,  ...,  2.3800,  2.3627,  2.3627]],\n",
       " \n",
       "          [[ 0.4208,  0.3858,  0.3156,  ...,  2.7005,  2.6829,  2.6829],\n",
       "           [ 0.2630,  0.3156,  0.2630,  ...,  2.7005,  2.6829,  2.6829],\n",
       "           [ 0.0701,  0.2279,  0.1929,  ...,  2.7005,  2.6829,  2.6829],\n",
       "           ...,\n",
       "           [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303],\n",
       "           [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303],\n",
       "           [ 2.5076,  2.5076,  2.5076,  ...,  2.6479,  2.6303,  2.6303]]],\n",
       " \n",
       " \n",
       "         [[[-1.7557, -1.7393, -1.7393,  ..., -0.5101, -0.4445, -1.1493],\n",
       "           [-1.7393, -1.7393, -1.7393,  ..., -0.4937, -0.1331, -0.5429],\n",
       "           [-1.7557, -1.7557, -1.7557,  ..., -0.1167,  0.0144, -0.2642],\n",
       "           ...,\n",
       "           [ 2.0632,  2.1615,  1.5059,  ...,  1.9976,  1.7026,  1.1945],\n",
       "           [ 2.0468,  2.0468,  1.6206,  ...,  2.1451,  2.3418,  2.3254],\n",
       "           [ 1.9812,  1.8993,  1.9321,  ...,  2.3090,  2.3254,  2.2926]],\n",
       " \n",
       "          [[ 2.1891,  2.2065,  2.2065,  ...,  1.0088,  1.6510,  1.9635],\n",
       "           [ 2.2238,  2.2412,  2.2412,  ...,  1.4428,  1.4081,  1.1130],\n",
       "           [ 2.2412,  2.2585,  2.2585,  ...,  1.4948,  1.5295,  0.9221],\n",
       "           ...,\n",
       "           [ 1.2171,  1.4601,  0.4187,  ...,  0.3319,  0.1931, -0.2061],\n",
       "           [ 0.8353,  0.8179,  0.2972,  ...,  0.8526,  1.0436,  1.0088],\n",
       "           [ 0.4534,  0.2972,  0.5402,  ...,  1.4601,  1.2866,  1.0262]],\n",
       " \n",
       "          [[ 2.8232,  2.8232,  2.8408,  ..., -0.6138,  0.4208,  1.5607],\n",
       "           [ 2.8408,  2.8408,  2.8232,  ..., -0.1754, -0.3332, -0.2630],\n",
       "           [ 2.8583,  2.8057,  2.7881,  ..., -0.3332, -0.1754, -0.8242],\n",
       "           ...,\n",
       "           [-1.0171, -0.6839, -1.2626,  ..., -1.3327, -1.2100, -1.2801],\n",
       "           [-0.9820, -0.7891, -1.2626,  ..., -1.4905, -1.3327, -1.3152],\n",
       "           [-1.2450, -1.2626, -1.0872,  ..., -1.1924, -1.3327, -1.3503]]],\n",
       " \n",
       " \n",
       "         [[[-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "           [-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "           [-1.7557, -1.7557, -1.7557,  ..., -1.7557, -1.7557, -1.7557],\n",
       "           ...,\n",
       "           [-0.6576, -0.1495, -0.3462,  ...,  0.0144, -0.2314, -0.7887],\n",
       "           [-0.6740, -0.3626, -0.8051,  ...,  0.7356, -0.1331, -0.4773],\n",
       "           [-0.5920, -0.5101, -0.7231,  ...,  0.5225, -0.4281, -0.0839]],\n",
       " \n",
       "          [[-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "           [-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "           [-1.6988, -1.6988, -1.6988,  ..., -1.6988, -1.6988, -1.6988],\n",
       "           ...,\n",
       "           [-0.3623,  0.1584,  0.0889,  ...,  0.2625,  0.1063, -0.4144],\n",
       "           [-0.2756,  0.1063, -0.2061,  ...,  1.0262,  0.1931, -0.0499],\n",
       "           [-0.1888, -0.1367, -0.1020,  ...,  0.7659, -0.0673,  0.2972]],\n",
       " \n",
       "          [[-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "           [-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "           [-1.5607, -1.5607, -1.5607,  ..., -1.5607, -1.5607, -1.5607],\n",
       "           ...,\n",
       "           [-1.3152, -1.2626, -1.2275,  ..., -0.9645, -1.4029, -1.4379],\n",
       "           [-1.4905, -1.3853, -1.5081,  ..., -0.1754, -1.3152, -1.4029],\n",
       "           [-1.3853, -1.5081, -1.5256,  ..., -0.5085, -1.3853, -1.3678]]]]),\n",
       " tensor([7.3153, 5.7684, 6.0457, 4.7812, 4.9913, 4.2415, 4.9200, 7.2601, 4.7479,\n",
       "         6.0181, 4.7278, 4.9599, 4.7406, 5.9426, 3.6690, 5.2282, 3.9467, 5.6646,\n",
       "         5.3918, 5.6785, 5.5073, 6.6627, 7.5462, 6.0049, 6.9765, 5.7857, 5.6425,\n",
       "         6.5022, 5.7050, 6.3191, 5.1692, 5.2561, 7.7687, 7.7683, 6.6986, 4.2372,\n",
       "         5.6203, 7.3789, 4.9062, 5.7383, 5.7097, 5.2986, 5.7099, 6.3333, 6.8324,\n",
       "         3.5700, 5.8074, 5.0197, 4.2560, 6.5468, 5.9971, 6.4689, 3.8317, 4.9615,\n",
       "         5.0225, 6.0929, 6.0104, 4.2647, 6.1612, 5.3210, 4.7843, 5.8169, 7.2811,\n",
       "         5.8099, 6.1343, 6.3571, 5.9565, 5.1107, 5.7914, 5.2773, 4.0492, 6.2011,\n",
       "         6.9557, 6.1493, 5.2898, 5.3198, 5.6316, 5.8944, 5.0428, 6.2851, 5.6000,\n",
       "         6.6455, 5.6205, 7.2302, 6.8247, 4.1462, 6.8476, 6.5676, 5.7097, 5.9568,\n",
       "         4.7162, 6.3014, 5.3440, 6.4348, 4.7407, 5.0285, 5.6299, 6.3237, 5.5798,\n",
       "         5.2881, 6.0586, 7.2682, 5.1736, 6.3302, 6.3064, 5.6190, 6.5912, 5.9264,\n",
       "         5.9682, 5.9574, 6.4134, 5.5771, 5.7409, 6.4037, 4.6940, 5.5789, 6.0619,\n",
       "         6.4529, 6.1884, 4.8158, 5.2830, 5.6313, 6.7049, 5.8737, 5.2549, 4.7345,\n",
       "         4.7202, 6.1130], dtype=torch.float64),\n",
       " ('nice contrast in the trees. great captures.',\n",
       "  'interesting idea on your processing, not sure it works for me, think the sepia toned image on its own would work better.',\n",
       "  'great portrait and your bw conversion was nicely done.',\n",
       "  'nice light and detail. i like that you havent been predictable and aligned your flowers on the thirds lines',\n",
       "  'a sharpen image effect and more light wil be good',\n",
       "  'im confused by this one. that red kiteshaped neon thing looks strangly out of place but i cant figure out what it is to begin with.',\n",
       "  'great find. i wish it was more dramatic in colour, though.or, black and white.',\n",
       "  'great desat! what a cool place',\n",
       "  'certainly more than one light source here, though a nice enough night pic',\n",
       "  'this is screaming for an adjustment of curves. it would enrich the picture like you cant believe. then increase the contrast. i just did it in photoshop and it looked cool as it is, it seems so washed out. bummer, cause i like the idea.',\n",
       "  'cute critters arent they.but the midday light it too harsh here.',\n",
       "  '. i just called to say . i love it ! . the phones are just a bit blurry .',\n",
       "  'the grain is a bit too much for me. like the ghost effect you created here.',\n",
       "  'doesnt sparkle, feels a little flat. subjects like this need to have absolutely perfect subjects and this one shows some dameagescratching.',\n",
       "  'wow way overexposed or saturated or something, even tho i like the take on the challene',\n",
       "  'nice job! i love the fabrick texture, lol',\n",
       "  'a little dark, but still a great looking photo good work',\n",
       "  'unfortunately, im not liking this photo much. i think it has a lot of potential, if there were a bit more shadow detail andor the light in the windows wasnt blown out.',\n",
       "  'nice timing with the lights. i like that we can see the movement.',\n",
       "  'nice, this looks like a beautiful place. unfortunately, the photo looks a bit overprocessed for me.',\n",
       "  'for mardi gras really need the colors.',\n",
       "  'has a definate mood to this one.',\n",
       "  'damned, great details! i am astonished to see such a good contrast since ive always noticed s has made blurry images.',\n",
       "  'from what youve put down as digital processing, i cant see any glaring problems. a good use of usm, as the image doesnt seem too oversharp, and i cant tell where youve cloned or smudged.',\n",
       "  'very good if the walls were white maby just a tad more cintrast if they are blue gray then not. over all well done',\n",
       "  'cute use of selective saturation. nice textures.',\n",
       "  'precious image, wonderful vibrant colors.',\n",
       "  'you know whats funny. i seem to recall some trash talkin which had me convinced that i wasnt going to have the blue',\n",
       "  'i would have chosen a picture with more yellow and not so much green.',\n",
       "  'love the creativity.tones and detail!',\n",
       "  'what a lovely warm color of brown i havent seen one that color before.',\n",
       "  'i do think a tad bit of saturation wouldve been nice.',\n",
       "  'quite the mood captured here. haunting in some ways.',\n",
       "  'enzo! i am thrilled for you! woo hoo on your blue!',\n",
       "  'now this is the way to use selective color . for a reason. nice job.',\n",
       "  'looks like a blurry picture of clouds to me.as a photo it is not good',\n",
       "  'jayson, you know how much i love some of your images, but this one just leaves me kind of flat. i have a feeling theres an amazing image in there somewhere i just cant see how to bring it out.',\n",
       "  'wow! this image is fantastic. the reflections in the glasses really add a unique feel. exposure and detail is excellent as well. i hope you place well!',\n",
       "  'the light from within is pretty well captured and the illumination of the walls works pretty well but i really dont see the moving light source in this but i may just be missing it',\n",
       "  'add some intensity with curves or levels in ps elements if you dont have photoshop.',\n",
       "  'you should have been making movies in germany in the s, thats impressive.',\n",
       "  'nice idea, but poor execution. why so soft?',\n",
       "  'it is much better than the original, but could be even better with just slight adjustments. tone down the softness just a bit and this one would have done much better for you.',\n",
       "  'nicely controlled from exposure to presentation. beautiful.',\n",
       "  'the pose is great,and a super quality image.',\n",
       "  'this photo is too contrasty, it makes the photo fake.',\n",
       "  'instinctive shadow wonder if it was planned this way? sad',\n",
       "  'jennifer looks very warm. interesting idea, worth a few extra points.',\n",
       "  'i get the idea but its not really working for me. maybe with a little more postproduction it wouldnt look so flat and soft.',\n",
       "  'neat. but kinda creepy.',\n",
       "  'very good still life a little harsh on color and sharpness though.',\n",
       "  'too dark and yellows could be more saturated, light is a bit harsh',\n",
       "  'seems a little grainy, so a good solution for this would be to make it black and white.',\n",
       "  'this one is a bit busy for m. lots of nice detail, but perhaps too much.',\n",
       "  'the desat here in my opinion fails to enhance the photo, and so serves more as a distraction in what would be otherwise a very nice picture.',\n",
       "  'a cracking photo! nice light and colour.',\n",
       "  'its gorgeous! a tad dark on my screen, but wonderful detail!',\n",
       "  'to much hue on it. collors look unreal',\n",
       "  'what a character. the pose is great and the sly grim makes this image. it is a pity that it is imho a bit too dark. i would have liked to see more detail.',\n",
       "  'good texture, and the grayscale was a nice choice.',\n",
       "  'good capture, i like this but taking the noise out with neat image or the like would have improved it quite a bit',\n",
       "  'i like this a lot. neat colors in the pads and the new leaves.',\n",
       "  'excellent ncapture. the colors and tones are amazing. a real beauty. well done.',\n",
       "  'you did a really nice job capturing the feel of the place silhouettes and all with a perfect exposure.',\n",
       "  'its a brilliant image . i love the stark whiteness of it and those excellent lines .',\n",
       "  'this is a great capture. my pick for yellow!',\n",
       "  'cool location.just a touch dark',\n",
       "  'oh the light! what a peaceful spirital image.',\n",
       "  'real nice, take it again and hdr it for the hdr category, nice as it is though.',\n",
       "  'its called a poptop. nice detail.',\n",
       "  'thats a really neat beachball. .',\n",
       "  'very interesting image. nice colours and sharpness, too.',\n",
       "  'i had this picked for the blue. wtg enzo!',\n",
       "  'im wondering if you pushed the color saturation too far as it looks a little grainy.',\n",
       "  'cute photo but not the best quality.',\n",
       "  'the soft shadowss are the best thing about this, for me.',\n",
       "  'didnt know they had nice light like this in ohio jk',\n",
       "  'wow! thats close! nicely captured texture.',\n",
       "  'technical aspects pretty clear, although some lost detail.',\n",
       "  'the success of this is not just the photograph itself, but the experimentation you did to capture what you saw. the softness and haziness is perfect for what you were trying to depict, and create a pleasing photo as well.',\n",
       "  'this has that quality that makes an image burn into ones memory. very powerful.',\n",
       "  'wonderful colours along with that light, photo has a great feel to it.',\n",
       "  'a bit overexposed, but im assume you intended that.',\n",
       "  'simply gorgeous, grats on a well deserved blue from the outtakes my faves are',\n",
       "  'very colorful and the black roses are good.',\n",
       "  'good lightning, but the picture is blurry. ikiymm',\n",
       "  'very interesting effect achieved by the feathered blue dot, but you know that, thats why you did it! very nice.',\n",
       "  'great light beams captured on the distant mesa',\n",
       "  'i think this one would have been soo much better in black and white,or some nice contrasty doutone.',\n",
       "  'i like the layered effect you have created here, especially using these colors which complement each other very well. with tulips you can never go wrong',\n",
       "  'decent motion captured, but not really what i call a blurry mess',\n",
       "  'it looks like an advertisement for a travel agency. i like the reflective mood of this photo.',\n",
       "  'glad to see you went full color, desat nature photograph just seems wrong.',\n",
       "  'great dof.good colors and tones.',\n",
       "  'i love the light and movement. great colors.',\n",
       "  'little soft.maybe the intent. colors dont pop out.',\n",
       "  'cool. the dark and light play well together here. does not scream abandoned to me.',\n",
       "  'wow! is that for real? it looks surreal.excellent colour and light',\n",
       "  'whew. difficult exposure, done nicely.',\n",
       "  'interesting photo and an original idea. good clarity and use of color.',\n",
       "  'i like the vivid clear colors in this one. .',\n",
       "  'great capture the sepia tone adds to the images impact.',\n",
       "  'good use of mottled light, almost spiritual.',\n",
       "  'old memories in penetrating bw tones.',\n",
       "  'dpnt know about the blue color but its quite impressive and the texture of the towers are fantastic.',\n",
       "  'she seems a little too close to the edge of the photo.',\n",
       "  'the strength of this photo is definitely in its colours. great balance between the warm and cold tones.',\n",
       "  'janey! awesome unique image and great finish.',\n",
       "  'a very moving image with ideal choice for bw',\n",
       "  'shadows a bit distracting.just a bit.but otherwise absolutely brilliant.great tone!',\n",
       "  'i love this one, the only thing is the pink highlights, but that may be my monitor.',\n",
       "  'very graphic, a bit noisy. would benefit from neatimage or noiseninja.',\n",
       "  'lovely place and a really good picture. nice colors o',\n",
       "  'very good quality pro photo!',\n",
       "  'very cool photo love the colors, shadows. good job.',\n",
       "  'excellent mood, i love this kind of portraits a lot.',\n",
       "  'great pov. the vignetting effect creates an interesting mood.',\n",
       "  'neat looking arches. good capture.',\n",
       "  'wow, i love the contrast and gradient. great job !',\n",
       "  'love the color contrasts. the childrens faces could be a little clearer and thier expressions could be better.',\n",
       "  'i love foggy morning scenes, this is just beautiful.',\n",
       "  'this is so glowing and gorgeous, what fantastic colors',\n",
       "  'its all real. just used levelshue, saturation adjustments and neatimage.',\n",
       "  'beautiful colors, the red seems so vibrant. nice thought process with this photo.',\n",
       "  'this is just too cute! a bit bright, but cute! interesting idea. o',\n",
       "  'peaceful. interesting. especially that slight orange with the green.',\n",
       "  'white balance looks yellow, funny idea though.',\n",
       "  'wow love how this is put together! good editing. great colors! and you look fine lol. fun pic!')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n",
      "torch.Size([128, 512])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "from train.models.encoder_resnet import EncoderResnet\n",
    "encoder = EncoderResnet(512)\n",
    "out, mos = encoder(dataset[0])\n",
    "print(mos.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common.config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\main.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseq2seq\u001b[39;00m \u001b[39mimport\u001b[39;00m Seq2seq\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# 단어 사전 생성\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_comments \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(train_data[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\train\\models\\seq2seq.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecoder_seq\u001b[39;00m \u001b[39mimport\u001b[39;00m DecoderSeq\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtime_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_model\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\train\\models\\decoder_seq.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtime_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDecoderSeq\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, vocab_size, wordvec_size, hidden_size):\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\common\\time_layers.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding: utf-8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m sigmoid\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\common\\layers.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m softmax, cross_entropy_error\n\u001b[0;32m      4\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMatMul\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, W):\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\common\\functions.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding: utf-8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnp\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(x):\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mx))\n",
      "File \u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\common\\np.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding: utf-8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m GPU\n\u001b[0;32m      5\u001b[0m \u001b[39mif\u001b[39;00m GPU:\n\u001b[0;32m      6\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'common.config'"
     ]
    }
   ],
   "source": [
    "from train.models.seq2seq import Seq2seq\n",
    "# 단어 사전 생성\n",
    "all_comments = ' '.join(train_data['comments']).split()\n",
    "vocab = set(all_comments)\n",
    "vocab = ['<PAD>', '<SOS>', '<EOS>'] + list(vocab)\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbbfc72-534d-46d7-b63e-56d28a43b04e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36b9f43-93c5-4c1f-bb4f-e3dae2392e3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\2023 Dacon Samsung image captioning\\main.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 손실함수\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[39m=\u001b[39mword2idx[\u001b[39m'\u001b[39m\u001b[39m<PAD>\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 학습\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/2023%20Dacon%20Samsung%20image%20captioning/main.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(CFG[\u001b[39m'\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2idx' is not defined"
     ]
    }
   ],
   "source": [
    "# 손실함수\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n",
    "\n",
    "\n",
    "\n",
    "# 학습\n",
    "\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for imgs, comments in loop:\n",
    "        # imgs = imgs.float()\n",
    "        \n",
    "        # Batch Preprocessing\n",
    "        comments_tensor = torch.zeros((len(comments), len(max(comments, key=len)))).long()\n",
    "        comments_tensor.shape()\n",
    "        break\n",
    "    #     for i, comment in enumerate(comments):\n",
    "    #         tokenized = ['<SOS>'] + comment.split() + ['<EOS>']\n",
    "    #         comments_tensor[i, :len(tokenized)] = torch.tensor([word2idx[word] for word in tokenized])\n",
    "    #         # print(comments_tensor.size())\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    #     vocab_size = len(vocab)\n",
    "    #     wordvec_size = len(comments_tensor[-1])\n",
    "    #     hidden_size = 512\n",
    "    #     model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n",
    "\n",
    "    #     loss = model.forward(dataset, comments)\n",
    "    #     model.backward()\n",
    "    #     optimizer.update(model.params, model.grads)\n",
    "    #     total_loss += loss\n",
    "    #     # Forward & Loss\n",
    "    #     start_id = comments_tensor[0]\n",
    "    #     correct = comments_tensor[1:]\n",
    "    #     predicted_comments = model.generate(dataset, start_id, len(correct))\n",
    "    #     loss = criterion(predicted_comments.view(-1, len(vocab)), comments_tensor.view(-1))\n",
    "\n",
    "    #     # Backpropagation\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     total_loss += loss.item()\n",
    "    #     loop.set_description(f\"Epoch {epoch + 1}\")\n",
    "    #     loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # print(f\"Epoch {epoch + 1} finished with average loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864072e8-85dc-435d-9198-5b9e1f61bd24",
   "metadata": {},
   "source": [
    "## Inference & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881eb92-a172-479e-92e2-38f852a488e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/open/test.csv')\n",
    "test_dataset = d.CustomDataset(test_data, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "predicted_mos_list = []\n",
    "predicted_comments_list = []\n",
    "\n",
    "def greedy_decode(model, image, max_length=50):\n",
    "    image = image.unsqueeze(0)\n",
    "    mos, _ = model(image)\n",
    "    output_sentence = []\n",
    "    \n",
    "    # 시작 토큰 설정\n",
    "    current_token = torch.tensor([word2idx['<SOS>']])\n",
    "    hidden = None\n",
    "    features = model.cnn(image).view(image.size(0), -1)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        embeddings = model.embedding(current_token).unsqueeze(0)\n",
    "        combined = torch.cat([features.unsqueeze(1), embeddings], dim=2)\n",
    "        out, hidden = model.lstm(combined, hidden)\n",
    "        \n",
    "        output = model.fc(out.squeeze(0))\n",
    "        _, current_token = torch.max(output, dim=1)\n",
    "\n",
    "        # <EOS> 토큰에 도달하면 멈춤\n",
    "        if current_token.item() == word2idx['<EOS>']:\n",
    "            break\n",
    "\n",
    "        # <SOS> 또는 <PAD> 토큰은 생성한 캡션에 추가하지 않음\n",
    "        if current_token.item() not in [word2idx['<SOS>'], word2idx['<PAD>']]:\n",
    "            output_sentence.append(idx2word[current_token.item()])\n",
    "     \n",
    "    return mos.item(), ' '.join(output_sentence)\n",
    "\n",
    "# 추론 과정\n",
    "with torch.no_grad():\n",
    "    for imgs, _, _ in tqdm(test_loader):\n",
    "        for img in imgs:\n",
    "            img = img.float()\n",
    "            mos, caption = greedy_decode(model, img)\n",
    "            predicted_mos_list.append(mos)\n",
    "            predicted_comments_list.append(caption)\n",
    "\n",
    "# 결과 저장\n",
    "result_df = pd.DataFrame({\n",
    "    'img_name': test_data['img_name'],\n",
    "    'mos': predicted_mos_list,\n",
    "    'comments': predicted_comments_list  # 캡션 부분은 위에서 생성한 것을 사용\n",
    "})\n",
    "\n",
    "# 예측 결과에 NaN이 있다면, 제출 시 오류가 발생하므로 후처리 진행 (sample_submission.csv과 동일하게)\n",
    "result_df['comments'] = result_df['comments'].fillna('Nice Image.')\n",
    "result_df.to_csv('submit.csv', index=False)\n",
    "\n",
    "print(\"Inference completed and results saved to submit.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
